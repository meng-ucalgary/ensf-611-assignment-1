{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Lab1 - Scikit-learn\n",
    "Author: *BHAVYAI GUPTA*\n",
    "\n",
    "## 1. Overview\n",
    "\n",
    "At the end, you are asked to answer the following questions in **Section 5.1 Questions** in the notebook:\n",
    "\n",
    "1. For each task (classification and regression), which model performs best on the validation data using all features?\n",
    "2. For each task (classification and regression), which model performs best on the validation data using two principal components?\n",
    "3. In each task (classification and regression), for each model, how do full feature and two principal component model scores compare on the validation data?\n",
    "4. Do any of the models underfit or overfit? Provide examples."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Function definitions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_classifier_accuracy(model, X, y):\n",
    "    '''Calculate train and validation accuracy of classifier (model)\n",
    "        \n",
    "        Splits feature matrix X and target vector y \n",
    "        with sklearn train_test_split() and random_state=956.\n",
    "        \n",
    "        model (sklearn classifier): Classifier to train and evaluate\n",
    "        X (numpy.array or pandas.DataFrame): Feature matrix\n",
    "        y (numpy.array or pandas.Series): Target vector\n",
    "        \n",
    "        returns: training accuracy, validation accuracy\n",
    "    '''\n",
    "    \n",
    "    # split the data into training set and validation set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=956)\n",
    "    \n",
    "    # fit the model using training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # predict the data on training set\n",
    "    y_train_predicted = model.predict(X_train)\n",
    "\n",
    "    # get the training accuracy\n",
    "    acc_train = accuracy_score(y_train, y_train_predicted)\n",
    "\n",
    "    # predict the data on validation set\n",
    "    y_test_predicted = model.predict(X_test)\n",
    "    \n",
    "    # get the validation accuracy\n",
    "    acc_test = accuracy_score(y_test, y_test_predicted)\n",
    "\n",
    "    return (acc_train, acc_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_regressor_mse(model, X, y):\n",
    "    '''Calculate train and validation mean-squared error (mse) of regressor (model)\n",
    "        \n",
    "        Splits feature matrix X and target vector y \n",
    "        with sklearn train_test_split() and random_state=956.\n",
    "        \n",
    "        model (sklearn regressor): Regressor to train and evaluate\n",
    "        X (numpy.array or pandas.DataFrame): Feature matrix\n",
    "        y (numpy.array or pandas.Series): Target vector\n",
    "        \n",
    "        returns: training mse, validation mse\n",
    "    '''\n",
    "    \n",
    "    # split the data into training set and validation set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=956)\n",
    "    \n",
    "    # fit the model using training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # predict the data on training set\n",
    "    y_train_predicted = model.predict(X_train)\n",
    "\n",
    "    # get the training mean squared error\n",
    "    mse_training = mean_squared_error(y_train, y_train_predicted)\n",
    "\n",
    "    # predict the data on validation set\n",
    "    y_test_predicted = model.predict(X_test)\n",
    "\n",
    "    # get the validation mean squared error\n",
    "    mse_validation = mean_squared_error(y_test, y_test_predicted)\n",
    "\n",
    "    return (mse_training, mse_validation)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def get_n_principal_components(X, n=2):\n",
    "    '''Extracts n principal componets from feature matrix X using sklearn PCA.\n",
    "        X (pandas.DataFrame): A feature matrix\n",
    "        n (int): number of principal components\n",
    "        \n",
    "        returns: feature matrix with n columns as numpy.array\n",
    "    '''\n",
    "    \n",
    "    # instantiate the model with hyperparameter\n",
    "    model = PCA(n_components=n)\n",
    "    \n",
    "    # fit the model\n",
    "    model.fit(X)\n",
    "\n",
    "    # transform the Feature Matrix\n",
    "    X_nD = model.transform(X)\n",
    "    \n",
    "    return X_nD"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Classification\n",
    "\n",
    "Using yellowbrick spam - classification  \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/spam.html\n",
    "\n",
    "The goal is to compare `LogisticRegression(max_iter=2000)` and `RandomForestClassifier(random_state=88)` classification performance on a validation set with full features and first two principal components."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1 Load data\n",
    "\n",
    "Load the spam data set into feature matrix `X` and target vector `y`.\n",
    "\n",
    "Call `get_n_principal_components()` to obtain feature matrix `X_2D` containing the first two principal components.\n",
    "\n",
    "Print dimensions and type of `X`, `y`, and `X_2D`.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from yellowbrick.datasets.loaders import load_spam\n",
    "\n",
    "# loading spam dataset into feature matrix X and target vector y\n",
    "X, y = load_spam()\n",
    "\n",
    "# PCA dimensionality reduction on X\n",
    "X_2D = get_n_principal_components(X, 2)\n",
    "\n",
    "print(\"Dimension of X    = {0}\\nDimension of y    = {1}\\nDimension of X_2D = {2}\".format(X.shape, y.shape, X_2D.shape))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dimension of X    = (4600, 57)\n",
      "Dimension of y    = (4600,)\n",
      "Dimension of X_2D = (4600, 2)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2 Train and evaluate models\n",
    "\n",
    "1. Import `LogisticRegression` and `RandomForestClassifier` from sklearn\n",
    "2. Instantiate models `LogisticRegression(max_iter=2000)` and `RandomForestClassifier(random_state=88)` in a list.\n",
    "3. create a for loop iterating the models list:\n",
    "    - Call `get_classifier_accuracy()` using all features, i.e. `X`.\n",
    "    - Call `get_classifier_accuracy()` using PCA features, i.e. `X_2D`.\n",
    "    - Print training and validation accuracy for both. Limit output to **3 decimal places**."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# create the list of models\n",
    "model_list = [LogisticRegression(max_iter=2000), RandomForestClassifier(random_state=88)]\n",
    "\n",
    "# loop over the model_list to get accuracy\n",
    "for model in model_list:\n",
    "    print(\"{} model\".format(model.__class__.__name__))\n",
    "    \n",
    "    # calculate the accuracy using all features\n",
    "    acc_train_all, acc_test_all = get_classifier_accuracy(model, X, y)\n",
    "    print(\"  - Using all features\")\n",
    "    print(\"    1. Training accuracy = {0:.3f}\".format(acc_train_all))\n",
    "    print(\"    2. Validation accuracy = {0:.3f}\\n\".format(acc_test_all))\n",
    "\n",
    "\n",
    "    # calculate the accuracy using PCA features\n",
    "    acc_train_pca, acc_test_pca = get_classifier_accuracy(model, X_2D, y)\n",
    "    print(\"  - Using PCA features\")\n",
    "    print(\"    1. Training accuracy = {0:.3f}\".format(acc_train_pca))\n",
    "    print(\"    2. Validation accuracy = {0:.3f}\\n\".format(acc_test_pca))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LogisticRegression model\n",
      "  - Using all features\n",
      "    1. Training accuracy = 0.934\n",
      "    2. Validation accuracy = 0.917\n",
      "\n",
      "  - Using PCA features\n",
      "    1. Training accuracy = 0.729\n",
      "    2. Validation accuracy = 0.725\n",
      "\n",
      "RandomForestClassifier model\n",
      "  - Using all features\n",
      "    1. Training accuracy = 0.999\n",
      "    2. Validation accuracy = 0.944\n",
      "\n",
      "  - Using PCA features\n",
      "    1. Training accuracy = 0.999\n",
      "    2. Validation accuracy = 0.771\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.3 Plot PCA feautures\n",
    "Use a Seaborn `scatterplot` to visulaize the two PCA components using the lables in `y` as `hue`.\n",
    "\n",
    "Label x- and y-axis and add a title."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# TODO: ADD YOUR CODE HERE"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Regression\n",
    "\n",
    "Using yellowbrick energy - regression  \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/energy.html\n",
    "\n",
    "The goal is to compare `LinearRegression()` and `RandomForestRegressor(random_state=88)` regression performance on a validation set with full features and first two principal components."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.1 Load data\n",
    "\n",
    "Load the energy data set into feature matrix `X` and target vector `y`.\n",
    "\n",
    "Call `get_n_principal_components()` to obtain feature matrix `X_2D` containing the first two principal components.\n",
    "\n",
    "Print dimensions and type of `X`, `y`, and `X_2D`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# TODO: ADD YOUR CODE HERE"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.2 Train and evaluate models\n",
    "\n",
    "1. Import `LinearRegression` and `RandomForestRegressor` from sklearn\n",
    "2. Instantiate models `LinearRegression()` and `RandomForestRegressor(random_state=88)` in a list.\n",
    "3. create a for loop iterating the models list:\n",
    "    - Call `get_regressor_mse()` using all features, i.e. `X`.\n",
    "    - Call `get_regressor_mse()` using PCA features, i.e. `X_2D`.\n",
    "    - Print training and validation accuracy for both. Limit output to **1 decimal place**."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# TODO: ADD YOUR CODE HERE"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.3 Plot PCA feautures\n",
    "Use a Seaborn `scatterplot` to visulaize the two PCA components using the values in `y` as `hue` and `size`.\n",
    "\n",
    "Label x- and y-axis and add a title."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# TODO: ADD YOUR CODE HERE"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Observations/Interpretation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.1 Questions\n",
    "1. For each task (classification and regression), which model performs best on the validation data using all features?\n",
    "\n",
    "**Classification:**  \n",
    "*ADD YOUR FINDINGS HERE*\n",
    "\n",
    "**Regression:**  \n",
    "*ADD YOUR FINDINGS HERE*\n",
    "\n",
    "\n",
    "2. For each task (classification and regression), which model performs best on the validation data using two principal components?\n",
    "\n",
    "**Classification:**  \n",
    "*ADD YOUR FINDINGS HERE*\n",
    "\n",
    "**Regression:**  \n",
    "*ADD YOUR FINDINGS HERE*\n",
    "\n",
    "3. In each task (classification and regression), for each model, how do full feature and two principal component model scores compare on the validation data?\n",
    "\n",
    "**Classification:**  \n",
    "*ADD YOUR FINDINGS HERE*\n",
    "\n",
    "**Regression:**  \n",
    "*ADD YOUR FINDINGS HERE*\n",
    "\n",
    "4. Do any of the models underfit or overfit? Provide examples.\n",
    "**Underfitting**   \n",
    "*ADD YOUR FINDINGS HERE*\n",
    "\n",
    "**Overfitting**   \n",
    "*ADD YOUR FINDINGS HERE*\n",
    "\n",
    "### 5.2 Conclusion\n",
    "Conclude on any one pattern you see emerge in your answers to questions above. Include the data to justify your conclusion.\n",
    "\n",
    "\n",
    "*ADD YOUR FINDINGS HERE*\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. Reflection\n",
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challangeing, motivating\n",
    "while working on this assignment.\n",
    "\n",
    "\n",
    "*ADD YOUR THOUGHTS HERE*"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "interpreter": {
   "hash": "f4fde45515710cbe4f4cf44a8ddef1b298277709bd6c5462499553af68a98f2e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}